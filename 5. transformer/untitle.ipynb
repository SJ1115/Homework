{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3153],\n",
       "         [0.6936]],\n",
       "\n",
       "        [[0.9872],\n",
       "         [0.8483]],\n",
       "\n",
       "        [[0.9075],\n",
       "         [0.8698]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = lambda x: x\n",
    "k(8)\n",
    "torch.randn(3,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'de': 'Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten',\n",
       "  'en': 'A Republican strategy to counter the re-election of Obama'},\n",
       " {'de': 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.',\n",
       "  'en': 'Republican leaders justified their policy by the need to combat electoral fraud.'},\n",
       " {'de': 'Allerdings hält das Brennan Center letzteres für einen Mythos, indem es bekräftigt, dass der Wahlbetrug in den USA seltener ist als die Anzahl der vom Blitzschlag getöteten Menschen.',\n",
       "  'en': 'However, the Brennan Centre considers this a myth, stating that electoral fraud is rarer in the United States than the number of people killed by lightning.'},\n",
       " {'de': 'Die Rechtsanwälte der Republikaner haben in 10 Jahren in den USA übrigens nur 300 Fälle von Wahlbetrug verzeichnet.',\n",
       "  'en': 'Indeed, Republican lawyers identified only 300 cases of electoral fraud in the United States in a decade.'},\n",
       " {'de': 'Eins ist sicher: diese neuen Bestimmungen werden sich negativ auf die Wahlbeteiligung auswirken.',\n",
       "  'en': 'One thing is certain: these new provisions will have a negative impact on voter turn-out.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"valid.pkl\", 'rb') as f:\n",
    "    val = pickle.load(f,)\n",
    "\n",
    "val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = [dic[k] for dic in val for k in dic ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wmt14/de-en to /home/user6/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c56a99012e4b829f21f0a4c003ac15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499ab05cc6f84895b926d438ee114834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/658M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0cc37c05b04abd933243269140159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fd26cc92d24de986bb1b609c36d359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/80.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3044cefe521f4537b704358c97a2dd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/38.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6b1cfdcfc746f69ee5255cc5420052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #0:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04415f2d6554586bb3d5d9d954051ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #3:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec43b79fa0a4901ac683fdcb992338e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #1:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fead36376540239af40f9894d582b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #4:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9d4ebe4f7a47b8b13dbec6fbfbf37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files #2:   0%|          | 0/1 [00:00<?, ?obj/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac7b06c902b457d8732f97711a35c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d708e6cc8de4527b995a00dfef101cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4508785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd1bff5eb454718989b151fc004ff31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be129e1f54b4652b74059c523b9fcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wmt14 downloaded and prepared to /home/user6/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091bfd4fc6e74770a691000db9f8c3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 4508785\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3003\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "k = load_dataset(\"wmt14\", \"de-en\")\n",
    "k\n",
    "\n",
    "import pickle\n",
    "with open(\"valid.pkl\", 'wb') as f:\n",
    "    pickle.dump(k[\"validation\"][\"translation\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No such file or directory (os error 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user6/LSJ/transformer/untitle.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.109/home/user6/LSJ/transformer/untitle.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m Tokenizer(BPE())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.109/home/user6/LSJ/transformer/untitle.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m trainer \u001b[39m=\u001b[39m BpeTrainer(special_tokens \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m<unk>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<eos>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.109/home/user6/LSJ/transformer/untitle.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m tokenizer\u001b[39m.\u001b[39;49mtrain(total, trainer\u001b[39m=\u001b[39;49mtrainer)\n",
      "\u001b[0;31mException\u001b[0m: No such file or directory (os error 2)"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(BPE())\n",
    "trainer = BpeTrainer(special_tokens = [\"<unk>\", \"<sos>\", \"<eos>\", \"<pad>\"])\n",
    "tokenizer.train(\"val\", trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30, 100])\n"
     ]
    }
   ],
   "source": [
    "b = 16  # Batch\n",
    "l = 30  # Len of Sent\n",
    "e = 100 # Embed dim\n",
    "\n",
    "q = torch.randn(b, l, e)\n",
    "k = torch.rand_like(q); v = torch.rand_like(q)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30, 100])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.einsum(\"ble,ble->bl\", q, k)\n",
    "print(score.shape)\n",
    "##mask\n",
    "score = torch.softmax(score, axis=1)\n",
    "o = torch.einsum(\"ble,bl->ble\", v, score)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "s = torch.tensor(range(k)).to(torch.float)\n",
    "s_= 1/torch.sqrt(torch.tensor(k))\n",
    "print(torch.softmax(s,0))\n",
    "print(torch.softmax(s*s_,0))\n",
    "s_=torch.sqrt(torch.tensor(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Attention import SelfAttention\n",
    "import torch \n",
    "batch = 20\n",
    "sent_len = 40\n",
    "sent_len2 = 60\n",
    "embed = 200\n",
    "n_head = 6\n",
    "d_key = 100\n",
    "d_hidden = 200\n",
    "d_out = 200\n",
    "a = torch.randn(batch, sent_len, embed)\n",
    "b = torch.randn(batch, sent_len2, embed)\n",
    "attend = SelfAttention(d_hidden, mask=True)\n",
    "#attend(a,b,c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_q1 = torch.nn.Linear(embed, d_key*n_head, bias=False)\n",
    "W_k1 = torch.nn.Linear(embed, d_key*n_head, bias=False)\n",
    "W_v1 = torch.nn.Linear(embed, d_hidden*n_head, bias=False)\n",
    "W_o1 = torch.nn.Linear(n_head*d_hidden, d_out, bias=False)\n",
    "\n",
    "W_q2 = torch.randn(embed, n_head, d_key)\n",
    "W_k2 = torch.randn(embed, n_head, d_key)\n",
    "W_v2 = torch.randn(embed, n_head, d_hidden)\n",
    "W_o2 = torch.randn(n_head, d_hidden, d_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 40, 200])\n",
      "torch.Size([20, 40, 200])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "q = torch.einsum(\"ble, ecd->blcd\", a, W_q2)\n",
    "k = torch.einsum(\"ble, ecd->blcd\", a, W_k2)\n",
    "v = torch.einsum(\"ble, ech->blch\", a, W_v2)\n",
    "shape = q.shape\n",
    "#q = q.view(shape[0], shape[1], n_head, -1)#.transpose(0,2)\n",
    "#k = k.view(shape[0], shape[1], n_head, -1)#.transpose(0,2)\n",
    "#v = v.view(shape[0], shape[1], n_head, -1)#.transpose(0,2)\n",
    "o = attend(q, k, v)\n",
    "o = torch.einsum(\"blch, cho->blo\", o, W_o2)\n",
    "print(o.shape)\n",
    "\n",
    "q = torch.randn(5,3,2,1)\n",
    "k = torch.randn(5,3)\n",
    "#q  k.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 40, 600])\n",
      "torch.Size([20, 40, 6, 200])\n",
      "torch.Size([20, 40, 1200])\n",
      "0.03194117546081543\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "a = torch.randn(batch, sent_len, embed)\n",
    "b = torch.randn(batch, sent_len2, embed)\n",
    "\n",
    "\n",
    "### way1\n",
    "s = time()\n",
    "for i in range(100):\n",
    "    q = W_q1(a); k = W_k1(a); v = W_v1(a)\n",
    "    shape = q.shape\n",
    "    print(shape)\n",
    "    q = q.view(shape[0], shape[1], n_head, -1)#.transpose(0,2)\n",
    "    k = k.view(shape[0], shape[1], n_head, -1)#.transpose(0,2)\n",
    "    v = v.view(shape[0], shape[1], n_head, -1)#.transpose(0,2)\n",
    "    print(v.shape)\n",
    "    o = attend(q, k, v).view(shape[0], shape[1], -1)\n",
    "    print(o.shape)\n",
    "    #o = torch.einsum(\"blch, cho->blo\", o, W_o2)\n",
    "    o = W_o1(o)\n",
    "    break\n",
    "\n",
    "print(time()-s)\n",
    "\n",
    "### way2\n",
    "s = time()\n",
    "for i in range(100):\n",
    "    break\n",
    "    q = torch.einsum(\"ble, ecd->blcd\", a, W_q2)\n",
    "    k = torch.einsum(\"ble, ecd->blcd\", a, W_k2)\n",
    "    v = torch.einsum(\"ble, ech->blch\", a, W_v2)\n",
    "\n",
    "    o = attend(q, k, v)\n",
    "    o = torch.einsum(\"blch, cho->blo\", o, W_o2)\n",
    "\n",
    "print(time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 40, 200])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = torch.nn.LayerNorm(200)\n",
    "ll(o).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 40, 200])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.Attention import MultiHeadAttention\n",
    "\n",
    "M = MultiHeadAttention(num_head=n_head, in_dim=embed, hidden_dim=d_hidden, key_dim=d_key, out_dim=d_out)\n",
    "\n",
    "M(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  3, -1,  1],\n",
       "        [ 1,  1,  1,  3],\n",
       "        [ 3, -1, -1,  1],\n",
       "        [-1, -1,  3,  1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [1,-1,-1],  #1\n",
    "    [1,1,-1],   #2\n",
    "    [1,1,1],    #3\n",
    "    [-1,1,-1]   #4\n",
    "])\n",
    "b = torch.tensor([\n",
    "    [1,1,1],    #3\n",
    "    [1,-1,-1],  #1\n",
    "    [-1,1,-1],  #4\n",
    "    [1,1,-1]    #2\n",
    "])\n",
    "\n",
    "torch.einsum(\"ij,Ij->iI\", a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3).tril(diagonal=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5683,  0.9822],\n",
       "         [ 1.3979,  1.0357]],\n",
       "\n",
       "        [[-0.7038,  1.0138],\n",
       "         [ 0.0685, -0.0544]],\n",
       "\n",
       "        [[-0.5437,  0.7363],\n",
       "         [-0.1208, -0.5742]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "samp_q = torch.randn(4,3,2,1)\n",
    "samp_k = torch.randn(4,4,2,1)\n",
    "samp_v = torch.randn(4,4,2,2)\n",
    "samp_s = torch.einsum(\"blcd,bmcd->bclm\", samp_q, samp_k) / 3\n",
    "mask = torch.ones(3,4).to(torch.int).tril()\n",
    "samp_s = samp_s.masked_fill(mask == 0, -100)\n",
    "samp_s = torch.softmax(samp_s, axis=3)\n",
    "samp_o = torch.einsum(\"bmch,bclm->blch\", samp_v, samp_s)\n",
    "samp_s[0, 1, :, :]\n",
    "samp_o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 60, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20, 100])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.Layer import Encoder, Decoder\n",
    "from src.Model import Transformer\n",
    "\n",
    "batch = 20\n",
    "vocab_size = 100\n",
    "sent_len = 40\n",
    "sent_len2 = 60\n",
    "d_model = 200\n",
    "n_head = 6\n",
    "d_key = 100\n",
    "d_value = 200\n",
    "d_feed = 1024\n",
    "d_out = 200\n",
    "\n",
    "n_layer = 6\n",
    "each = True\n",
    "\n",
    "\"\"\"samp = torch.randn(batch, sent_len, embed)\n",
    "samp2 = torch.randn(batch, sent_len2, embed)\n",
    "\n",
    "sampEnc = Encoder(num_layers = n_layer, num_head=n_head, model_dim=embed, value_dim=d_value, key_dim=d_key, feed_dim=d_feed, return_each=each)\n",
    "sampDec = Decoder(num_layers = n_layer, num_head=n_head, model_dim=embed, value_dim=d_value, key_dim=d_key, feed_dim=d_feed, get_each=each)\n",
    "\n",
    "temp = sampEnc(samp)\n",
    "print(temp.shape) if not each else 0\n",
    "temp = sampDec(samp2, temp)\n",
    "print(temp.shape)\"\"\"\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=vocab_size, \n",
    "    max_len=sent_len + sent_len2,\n",
    "    num_layers=n_layer, \n",
    "    num_head=n_head,\n",
    "    model_dim=d_model,\n",
    "    value_dim=d_value, \n",
    "    key_dim=d_key,\n",
    "    feed_dim=d_feed,\n",
    "    dropout=.1, send_each=False, embed_share=True)\n",
    "\n",
    "samp = torch.randint(0, vocab_size, (batch, sent_len))\n",
    "samp2 = torch.randint(0, vocab_size, (batch, sent_len2))\n",
    "\n",
    "print(model(samp,samp2).size())\n",
    "\n",
    "model.predict(samp, max_len=20).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5965,  0.7076, -0.9089,  0.3866,  0.7745,  1.6758],\n",
       "         [ 2.5311,  0.4324, -0.2381, -0.4608, -0.6070,  0.0152],\n",
       "         [-1.2052, -1.2878, -0.9749,  0.6621, -0.7977,  1.7467]],\n",
       "\n",
       "        [[-0.6743,  0.2969,  0.0333,  2.3706, -0.0154, -1.5639],\n",
       "         [ 0.1228,  1.1158, -0.0349,  0.6484,  0.7532,  0.1696],\n",
       "         [-0.1603,  0.8922, -0.9002, -1.4138,  0.9581,  1.6844]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sin(torch.tensor(3))\n",
    "\n",
    "size = 10\n",
    "dim = 3\n",
    "\n",
    "k = torch.arange(size).repeat(dim,1).transpose(1,0)\n",
    "k #/ torch.tensor([1,-1])\n",
    "scale = torch.arange(dim)/dim\n",
    "scale = 1/ torch.pow(10000, scale)\n",
    "s = torch.sin(k * scale)\n",
    "c = torch.cos(k * scale)\n",
    "\n",
    "o = torch.cat((s,c), axis=0)\n",
    "o = o.reshape(size, -1)\n",
    "o.size()\n",
    "## shape = size * 2*dim\n",
    "Emb = torch.nn.Embedding(num_embeddings=5, embedding_dim=2*dim)\n",
    "\n",
    "samp = torch.tensor([[0,1,2],[3,4,0]])\n",
    "print(samp.size())\n",
    "Emb(samp) + o[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.SubLayer import PositionalEmbedding as Embedding\n",
    "import torch\n",
    "\n",
    "Emb = Embedding(vocab_size=100, embedding_dim=256, max_len=200)\n",
    "samp = torch.randint(0, 5, (3,8))\n",
    "Emb(samp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "#Emb.parameters\n",
    "#torch.sum(Emb.trigonal > 0)\n",
    "#lin = torch.nn.Linear(6, 5)\n",
    "\n",
    "torch.mean(torch.cat([torch.rand(3,2).unsqueeze(0) for i in range(3)], dim=0), dim=0)\n",
    "\n",
    "k = torch.randint(high=3, size=(3,2))\n",
    "print(k)\n",
    "k.argmax(dim=-1)\n",
    "\n",
    "torch.save(k, f='sample.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.load(\"sample.pt\",)\n",
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freshman01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1106a7a884f58e56a887236484c1329c4f1472833f8e9fd27949900edc3cb9df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
