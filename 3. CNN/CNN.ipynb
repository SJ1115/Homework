{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 17895\n",
      "train\t: torch.Size([156817, 58])\n",
      "train_label\t: torch.Size([156817])\n",
      "test\t: torch.Size([2210, 58])\n",
      "test_label\t: torch.Size([2210])\n",
      "dev\t: torch.Size([1101, 58])\n",
      "dev_label\t: torch.Size([1101])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17895, 300])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocess import load_data, build_wordvec\n",
    "\n",
    "data = 'sst1'\n",
    "dataset = load_data(data)\n",
    "\n",
    "for key, value in dataset.items():\n",
    "    if key == 'w2i':\n",
    "        print(f\"Vocab size : {len(value)}\")\n",
    "    else:\n",
    "        print(f\"{key}\\t: {value.size()}\")\n",
    "\n",
    "embed_mat = build_wordvec(dataset['w2i'], var=.01)\n",
    "embed_mat.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 110])\n",
      "torch.Size([5, 1, 33000])\n",
      "[torch.Size([5, 100, 108]), torch.Size([5, 100, 107]), torch.Size([5, 100, 106])]\n",
      "[torch.Size([5, 100]), torch.Size([5, 100]), torch.Size([5, 100])]\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(len(dataset['w2i']), 300)\n",
    "filt = [3,4,5]\n",
    "conv = nn.ModuleList([nn.Conv1d(1, 100, 300*k, stride=300, dtype=torch.float) for k in filt])\n",
    "FC = nn.Linear(1 * 100 * 3, 2, dtype=torch.float)\n",
    "\n",
    "input = dataset['train'][:5]\n",
    "print(input.shape)\n",
    "in_size = input.shape[1]\n",
    "x = emb(input).view(-1, 1, 300*in_size)\n",
    "print(x.shape)\n",
    "conv_out = [con(x) for con in conv]\n",
    "print([p.shape for p in conv_out])\n",
    "pool_out = [nn.functional.max_pool1d(con, in_size - k + 1).view(-1,100)  for con, k in zip(conv_out, filt)]\n",
    "print([p.shape for p in pool_out])\n",
    "x = torch.cat(pool_out, 1)\n",
    "\n",
    "x = FC(x)\n",
    "print(x.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss :  0.002: 100%|██████████| 5400/5400 [00:23<00:00, 231.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training : 0:00:23 spent.\n",
      "Accuracy of the Model on the 1000 test set: 91.90 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmNUlEQVR4nO3deXyc1X3v8c9vZjTaV1veZWQbgzGbCcKsAZIQYhJi0hIS094sbVKnaWiTJmkLDSGE29tLktss95amUJpXbloooblZnMTFJAQSQlhsdryB8YJ3yZK1L6OZ+d0/ZjQaLbbGRouf8ff9eunleZ7neHSOGb46Os95zjF3R0REgi801RUQEZHxoUAXEckTCnQRkTyhQBcRyRMKdBGRPKFAFxHJE5FcCpnZCuBbQBi4193vHHb9G8Db0oclwAx3rzrae06fPt3r6+uPtb4iIie1Z5999pC71452bcxAN7MwcBfwTmAPsN7M1rj7poEy7v6XWeX/HDhvrPetr69nw4YNOVRfREQGmNmuI13LZchlObDN3be7ewx4ALjuKOVvBP7j2KooIiJvVi6BPhfYnXW8J31uBDM7BVgA/OrNV01ERI7FeN8UXQX8wN0To100s9VmtsHMNjQ1NY3ztxYRObnlEuh7gbqs43npc6NZxVGGW9z9HndvcPeG2tpRx/RFROQ45RLo64HFZrbAzKKkQnvN8EJmtgSoBp4c3yqKiEguxgx0d48DNwHrgM3Ag+6+0czuMLOVWUVXAQ+4lm8UEZkSOc1Dd/e1wNph524bdnz7+FVLRESOVeCeFF2/s4WvPLQF/SIgIjJU4AL9xd2tfPux12nviU91VURETiiBC/Ta8kIAmjr7prgmIiInlsAF+rTSVKA3K9BFRIYIXqCXRQFo7opNcU1ERE4sgQv06WWpHvoh9dBFRIYIXKBXlxRgBoc61UMXEckWuECPhENUl0Q1hi4iMkzgAh2gMBIiFk9OdTVERE4ogQz0kBkJPVgkIjJEIAM9HDKSSQW6iEi2wAZ6QnkuIjJEIAPdDJIachERGSKQgR42DbmIiAwXzEAPGQkFuojIEIEM9JCZhlxERIYJZKCHQ4Y66CIiQwUy0EOGhlxERIYJZqCHNOQiIjJcIAM9bLopKiIyXE6BbmYrzGyrmW0zs5uPUOYDZrbJzDaa2f3jW82hQprlIiIyQmSsAmYWBu4C3gnsAdab2Rp335RVZjFwC3Cpux82sxkTVWFIjaEntTaXiMgQufTQlwPb3H27u8eAB4DrhpX5E+Audz8M4O6N41vNoVKP/quHLiKSLZdAnwvszjrekz6X7TTgNDN7wsyeMrMV41XB0YQ0hi4iMsKYQy7H8D6LgSuBecBvzOxsd2/NLmRmq4HVAPPnzz/ubxbWLBcRkRFy6aHvBeqyjuelz2XbA6xx93533wG8Sirgh3D3e9y9wd0bamtrj7fOmuUiIjKKXAJ9PbDYzBaYWRRYBawZVubHpHrnmNl0UkMw28evmkOZ6UlREZHhxgx0d48DNwHrgM3Ag+6+0czuMLOV6WLrgGYz2wQ8CvyVuzdPVKXDIbTaoojIMDmNobv7WmDtsHO3Zb124LPprwmnWS4iIiMF8knRkNZDFxEZIZCBrh66iMhIgQx0rYcuIjJScANdj/6LiAwRyEAPh7QeuojIcAENdI2hi4gMF8hA1ywXEZGRghvo6qGLiAwRyEAPa4MLEZERAhnoIa3lIiIyQiADXbNcRERGCmSghzTLRURkhGAGuhmuQBcRGSKQga4NLkRERgpkoIdCqZui6qWLiAwKZKCHzQA000VEJEswAz1daw27iIgMCmSgW6aHrkAXERkQyEAPhxToIiLDBTPQ0z10DbmIiAzKKdDNbIWZbTWzbWZ28yjXP2pmTWb2Qvrr4+Nf1UGhgR66NrkQEcmIjFXAzMLAXcA7gT3AejNb4+6bhhX9vrvfNAF1HCGcynM9LSoikiWXHvpyYJu7b3f3GPAAcN3EVuvoQhpDFxEZIZdAnwvszjrekz433PVm9pKZ/cDM6saldkcQGpjlojF0EZGM8bop+lOg3t3PAX4B/N/RCpnZajPbYGYbmpqajvubDcxy0ZCLiMigXAJ9L5Dd456XPpfh7s3u3pc+vBc4f7Q3cvd73L3B3Rtqa2uPp76AZrmIiIwml0BfDyw2swVmFgVWAWuyC5jZ7KzDlcDm8aviSJrlIiIy0pizXNw9bmY3AeuAMPAdd99oZncAG9x9DfAXZrYSiAMtwEcnsM6k81w3RUVEsowZ6ADuvhZYO+zcbVmvbwFuGd+qHZnG0EVERgrkk6Ka5SIiMlIgA70gvdxiLKFBdBGRAYEM9NLCMABdfYkpromIyIkjkIFeVpga+u/qi09xTUREThyBDvROBbqISEYgA71UPXQRkRECHejqoYuIDApmoEdTN0UV6CIigwIZ6JFwiKKCkIZcRESyBDLQIXVjtFPTFkVEMgIb6KWFEfXQRUSyBDbQyxToIiJDBDbQS6MR3RQVEckS2EAvjobp6dcYuojIgMAGekk0THdMgS4iMiCwgV4cDdOjQBcRyQhsoKd66BpDFxEZEOBAj2jIRUQkS2ADvbggTF88SUK7FomIAAEO9JL0ei6a6SIikhL4QNc4uohISk6BbmYrzGyrmW0zs5uPUu56M3Mzaxi/Ko6uOJpaQlczXUREUsYMdDMLA3cB1wBLgRvNbOko5cqBTwNPj3clRzPYQ1egi4hAbj305cA2d9/u7jHgAeC6Ucr9d+ArQO841u+IihXoIiJD5BLoc4HdWcd70ucyzOwtQJ27//xob2Rmq81sg5ltaGpqOubKZispSN8UVaCLiADjcFPUzELA14HPjVXW3e9x9wZ3b6itrX1T37ckPYaum6IiIim5BPpeoC7reF763IBy4CzgMTPbCVwErJnoG6PFmrYoIjJELoG+HlhsZgvMLAqsAtYMXHT3Nnef7u717l4PPAWsdPcNE1LjNN0UFREZasxAd/c4cBOwDtgMPOjuG83sDjNbOdEVPBIFuojIUJFcCrn7WmDtsHO3HaHslW++WmPLDLloDF1EBAjwk6LRcIhwyNRDFxFJC2ygmxklBdrkQkRkQGADHbTJhYhItkAHekk0TLemLYqIAAEP9OJoRDdFRUTSAh3o2ihaRGSQAl1EJE8EOtCLC3RTVERkQKADvbQwQpfG0EVEgIAHellhhM4+BbqICAQ80MuLIrT39NMX17CLiEigA72iuICkw+m3PoS7T3V1RESmVKADvbxocG2x9h4NvYjIyS3ggV6Qed3SHZvCmoiITL1AB3pFVg+9pUuBLiInt0AH+pAeugJdRE5ygQ707B76YQW6iJzkAh3ohZFw5nVLd0zTF0XkpBboQJ9bXcyqC+oAuPO/tnD6rQ+xeX/7FNdKRGRqBDrQwyHjzuvP4ZNXLsqce/VgxxTWSERk6uQU6Ga2wsy2mtk2M7t5lOt/amYvm9kLZvZbM1s6/lU9sr9+1+k89Jm3AnCwvXcyv7WIyAljzEA3szBwF3ANsBS4cZTAvt/dz3b3ZcBXga+Pd0XHqCOnzywnGgnx92u30NihUBeRk08uPfTlwDZ33+7uMeAB4LrsAu6ePXBdCkz6c/hmRiyeBOAbv3h1sr+9iMiUi4xdhLnA7qzjPcCFwwuZ2aeAzwJR4O3jUrvjFA0H+taAiMhxGbfkc/e73H0R8DfAraOVMbPVZrbBzDY0NTWN17fO+Or15wDQ3qt1XUTk5JNLoO8F6rKO56XPHckDwPtGu+Du97h7g7s31NbW5lzJXH3ggjreMr9KN0ZF5KSUS6CvBxab2QIziwKrgDXZBcxscdbhe4DXxq+Kx2ZWZREHcgh0d6ejt38SaiQiMjnGDHR3jwM3AeuAzcCD7r7RzO4ws5XpYjeZ2UYze4HUOPpHJqrCY6mrLmFPSw9vNHcftdy9j+/g7NsfZn9bzyTVTERkYuU0hu7ua939NHdf5O7/I33uNndfk379aXc/092Xufvb3H3jRFb6aD5yST2hENz72+1HLfdfr+wHYF+rAl1E8kPeTQeZU1XMpYum89jWpqPuYmRmAGijIxHJF3kX6AAXL5rGGy3dNB9lBUZL/6k8F5F8kZeBPqOiCMhtSV310EUkX+RloFeXpDa+ONx95Fks6REXbS4tInkjTwM9CsDho+wzaulBF8W5iOSLvAz0qnQPvfVoG0ene+iJpCJdRPJDXgZ6TelAD/0oQy7pP/sTyUmokYjIxMvLQC8uCBONhI4+5JJO9P6Eeugikh/yMtDNjOqSAlo6xx5Dj6uHLiJ5Ii8DHWB+TQnbD3Ud8fpADz2mQBeRPJG3gX7W3Eo27Ws/Yg98INDjGnIRkTyRt4F+9txKevoT7DhCLz0z5JJUD11E8kPeBvqcqmIAGjv6Rr0+OOSiHrqI5Ie8DfTK4tRc9Laeo695rpuiIpIvTtpAH1htUfPQRSRf5H2gtx7h4aLBB4s05CIi+SFvA70kGqYgbJkeursPuUE6+GCReugikh/yNtDNjMrigkyg3/v4Dt72vx7j1682sfNQV2YNF01bFJF8EZnqCkykiuIC2tOBvn5nCwAf+c4zAFy8cBoA//joNvYc7uabq86bmkqKiIyTvO2hA1QVF9DaM/rj/9mrLP74hX2TVSURkQmTU6Cb2Qoz22pm28zs5lGuf9bMNpnZS2b2iJmdMv5VPXY1pVGaj7CeS5/GzkUkz4wZ6GYWBu4CrgGWAjea2dJhxZ4HGtz9HOAHwFfHu6LHY0ZFUebBooGboAOyt6cbWD9dRCTIcumhLwe2uft2d48BDwDXZRdw90fdvTt9+BQwb3yreXxmlhfR0hWjL57IPOo/oLlz8AnS0PC0FxEJoFwCfS6wO+t4T/rckXwM+K83U6nxMrOiEICmjr4RPfSuWCLzuq8/gYhI0I3rLBcz+29AA3DFEa6vBlYDzJ8/fzy/9ahmVhQBcLC976gPEPXFNZ4uIsGXSw99L1CXdTwvfW4IM7sK+AKw0t1HXRHL3e9x9wZ3b6itrT2e+h6TGeke+msHO/jl5oOjljn/lGriSdfeoiISeLkE+npgsZktMLMosApYk13AzM4D7iYV5o3jX83jM9BDv/mHL496/aKFNVx1xkwAYuqli0jAjRno7h4HbgLWAZuBB919o5ndYWYr08W+BpQB/2lmL5jZmiO83aSqKYkSDh35hmdLV4zCSOqf4EiBHk8kuffx7fTFNc4uIie2nMbQ3X0tsHbYuduyXl81zvUaF6GQjTqU8r5lc/jxC/to7owRTQd6KrALuO6uJ+jqi/PLz6ZuAzy76zB/9/PNnDqjjCtPnzGZ1RcROSZ5/aRotoGhFYD66aUANGf10AdujL64u5VtjZ2ZsgNrwfT2a0hGRE5sJ02gf3PVMq5bNgeAGeWpsfUz51Rk9dBHD+z23nj6uoZcROTElteLcwH85VWn8dOX9lFWGGFaaWrWS0dvPz/788uYW1XM0ztSi3YND+yeWILiaDizuJemNorIiS7vA/3TVy3m01ctBmB2Zapn3hVLcNbcSgAKC1I99J7Y0EBv7OjllGmltPemAl2zYETkRHfSDLkAfOjiU/ijS+v52GULMucKw6l/gvf/85NDyg6sAdPeMzDkokAXkRNb3vfQsxUVhPnSe88ccm6ghz7coYFA7x0YctEYuoic2E6qHvpoouFw5nX2sMon73uOp7c3D46ha5aLiJzgTvpAL4gMPnjUHYsPufYn39swOIau9dNF5AR30gd6OGsZxo7eoYHe05/InFMPXUROdCd9oC+eWc7Kc1Pz0w93D93dqD/hGkMXkcA46QMdyDxwdLi7f8S1gVku9z39Btd86/FJrZeIyLFQoAMl0dRkn+xt6QZ09A6G/Ob97bhrmV0ROTEp0IHSwtRMl898/4UR14av7XW0jTJERKaSAp3BHnouNNtFRE5UCnQGe+i50P6jInKiUqADJQVH76Fnb5LRF0/yse+uZ8U3fzPR1RIROSYKdKBkjB56dUlB5nVfPMkjWxrZcqBj1LL9iSTP7moZ1/qJiORCgQ4UhEN8/urTRpy/9T1nADCnqjhzbqxVF7+2bivXf/tJthxoH99KioiMQYGe9sdZKzBmzl26gFf/7hru/P1zmJsO9ewHjEbb3u75Nw4DcLhr5Jx2EZGJpEBPKy4YOewSChnRSIilcyq48/qzgaHL6A4s3NXU0cc5t6/jmR0t7DncA0BPf3zE+4mITKScAt3MVpjZVjPbZmY3j3L9cjN7zsziZvb+8a/mxLOsNV1GUxhJBX72kMvAUgEv7G6lvTfOB+5+kv1tvQC0qIcuIpNszEA3szBwF3ANsBS40cyWDiv2BvBR4P7xruBk+tt3L+FfPtzA2endjLIN7j06OOTSmu6hD1zL1to98qlTEZGJlMsTNcuBbe6+HcDMHgCuAzYNFHD3nelrgX7qZvXliwB46+LpI3YoKowMbFU3eL61O0ZHb/+oSwYMX+hLRGSi5RLoc4HdWcd7gAsnpjonhqKCMEXDxtQHAv1T9z+XObfmhX388Xc3jPoeoy30JSIykSZ1CzozWw2sBpg/f/5kfus3bbRhlZ+9tH/EuQvqqznc3a8hFxGZdLncFN0L1GUdz0ufO2bufo+7N7h7Q21t7fG8xZQZuCk64Oy5lcRHmbbY05+goiiSWXZXRGSy5BLo64HFZrbAzKLAKmDNxFbrxDN8M+nTZ5WPWq4nlqC0MEJXTIEuIpNrzEB39zhwE7AO2Aw86O4bzewOM1sJYGYXmNke4AbgbjPbOJGVngrR8NB/qoW1paOWWzKrgtJohK6+0QM9kXQOtvfi7vz2tUMkR+nli4gcj5zG0N19LbB22Lnbsl6vJzUUk7cKh42hVxQVEAnZkGGX76++iDPnVvKln2ykq2/0VRkfWP8GX/jRK5xbV8WLu1u59T1n8PG3LpzQuovIyUFPiuZo+INHRQVh5lUXDzl34cJplBVGKC0M03mEHvqW/alFvV7c3QrAjkNd419ZETkpKdCPw/uWzeH3zpvL/GmjD7uUFkZo6+nniW2HRlzbc7h7yHFojCdURURypUA/BiXR1EyXT155KuGQMb8m1UP/YEMdN1+zJFOurDA1kvWH9z494j32tvYMOQ4pz0VknCjQj8GVp6emWpYVpQL77LmVlBdG+PJ1Z/KnVyzKlCuNDk5xvPfx7QBsOdDOy3vaMot3DeiOaQckERkfk/pgUdD9ww3LuKGhObOU7g3n1/GuM2eNeKq0pHDwn/Xvfr6Zj15Sz4pvPj7qe+qJUhEZL+qhH4PiaJi3nT4jcxwKGVUl0RHlho+Ltwxb6yV7qV6t+SIi40WBPgEG1kkfsPXg0O3qTptZlnk9WqD39ic0P11EjpkCfQJceur0IcdPvt485HjxzMGnTIeHfzLpLPniQ3z5p3n3bJaITDAF+gQ4fVY5P/nUpZnjHz0/dOmb2ZVFmdftvUPnq7eke+zfe2oXkFp/va1H4+wiMjYF+gTJ3lh6YBej3/zV27j/4xdSEk3dNK0tLyQWT9LbPzjT5UC67MA4+6fue55zv/ww7hqCEZGjU6BPkNryQjbfsYK6msFgnz+thEtOnZ6Zz75geurBpPbewR54Y0cq0AfK/HLzQQBePdg5KfUWkeBSoE+g4miYx//67VQURVh57pzM+Uygp580zV5q90BbH0BmKmRBODVj5qntQ8fhRUSG0zz0SfD8bVcPeSJ0dmUxIYMz51bABvjGL1/lQxedQnNnjH3pJ0mjkRAdvf0MjLQcaO896vf42Uv7OG9+dWaOvIicfBTokyA87Pn+S0+dxuN/83YOtKXC++cv7efnw3Y/2t7Uxdm3P5w5Hm3f0gEH23u56f7nqSmN8twX3zmONReRINGQyxQwM+ZWFVNeVDBm2QsX1FBeFKGlK8b3178xJPhj8SQPPPMGj2xuBFIPMDV39o36Pq/sbeNffrN9fBogIick9dCnUMURAn15fQ3P7GxhWV0V3//Exdx4z1O8uKeVhzelbpCeN//tvLy3jWTSufmHLw/5uzubu5lWVpg57uyLEwkZ1/6f3wLw4UtOGbGdHkBTRx9tPTFOnTH6TkwicuJToE+h6WWDywb88M8u4Wcv7mf9zhZuaJjHMztb+KNL6wGoKY3y5PbBnvcld/4KGLpr0pzKIva19fLBu59kw61XUVUS5cXdrVz/7d9xxWmD+7ceaOvlV1sa6eiN8xfvWJw5f9XXf01bTz8773xP5lxXX5zSQn1ERIJC/7dOoUg4xCcuX8h3f7eTZfOqeMv8aiD1tOgVp9UyoyL1AFJ16eg9+e1Ng5tjLJ1Tyb62XuJJ57KvPMofXjQfd4gnnUe2NGbKbTnQwZd/uglgSKAPPLwUiyeJRkI0tvey/O8f4fb3LuWjly4Y34aLyITQGPoUu/maJWy+YwWhrBunoZBlwhygJr0AWP20Ev7xD87jpduvZsOtVwEwt6qYG5fXcdu1SzPlO/vi3P3r7fx6axO15YPDLwCf+LdnM68feuUAn7rvOeKJZObcwfRsmvU7DwPwDw+/mrm25UA7yaTT1tPPPz22LfP39rf10KNlgEWmnHroU8zMGGvTovPSPfedzd1ce87gfPbHPn8lJdFwJvyf/tt30Nuf4H13PcHh7n62HuzgE1cs5O5fj34z9E//PRXuqy8f3NP0rV99lLs/dD7P7koFekdfnEOdfew41MUN//wkX3rvUnYc6uJ7T+5iwbRSFs0o4+pv/IbLTp3Ov3/8wiHv3xNL8IUfv8znrj5d0ylFJkFOgW5mK4BvAWHgXne/c9j1QuB7wPlAM/BBd985vlU9eV1xWi0XLawZEuYA9dOHboE3Mx3sj//N2znrS+sAaDilhrd+rJZ9rT3sae3h4oXTcHf+IGs3pevuemLI+wz04mdXFrG/rZf/3LCHrvQeqS/vbcssVfCDZ/dkhnN+u+0Q7k4i6UTCqV/8HtlykB8+t5dHtzTyyOeupKZ05FLDE+GN5m4KC0KZf4/hvvrQFs6tq+JdZ84imXQ+cPeTvP/8eaxaPn9S6icyUcYMdDMLA3cB7wT2AOvNbI27b8oq9jHgsLufamargK8AH5yICp+MQiHjgdUX51y+rDDC0tkVbNrfzvmnVI8I0sNdMWpKo9z5+2fzme+/MGTXpFvfcwbrd7bw61eb+Naq8/inx7bxlYe2ZK7/8LnBhcayx+YBzvrSOrpiCc6aW8HrjV2Up3d2Otzdz2Vf+RUfaKijOBrm8sW1PLa1kRsa5vHk9ha2HmhnblUJ15w1i1OmlbD1YAf7W3t5y/xq1ry4l9caO1l9+UIqiwvY3dLDn//HcyxfMI3Xmzp577lziMWTXHHadNp6+qmrKeHyrz0KpLYGPL++mqvOmEl1SQHu0NwV458eex2AD198CmfNqWTDrsNs2HWYpMMHL6jLPDeQTDqhkPHU9mZ++uI+vnjtUh7edJCls8tHzAZyd1q6YpkZRgN/d7i9rT2UFISpPsIPt97+BIWR0IhNyYeX+c2rTbzjjJkjnnE4mqe2NxONhDL3aibSg+t3s7+tl09ftXjswsegtz8xYkOZ4V472MGi2rJR//3znY216JOZXQzc7u7vSh/fAuDu/zOrzLp0mSfNLAIcAGr9KG/e0NDgGzZsGIcmyGjauvvZuL+NSxZNP2q5V/a28Vc/eInN+9v5xz84L/NbQCLphENGV1+cP7vvOXY1dzG7spgntzczp7KIhvoa1ry4D4Az51TQ0hXLLEI2moKwURAODfnhEY2EiMWTQ8r0J478eSyMhJhbXTzkZvB4m1VRxFsXT+eJbYc41BXjkkXTeGxrEwBnzK5g8/52CsLGhy6qZ151MW+0dDO/poQ3Wrr57u92cvHCafTFExxo6+XqM2fxi00HOXNOBXOqiqktL+Rr67YC8LfvXsKM8iI27GrhgvoaNu/v4HevH+KlPW28b9kczp5XRVtPP2fMKudbj7zGlgMdFISNj15Sz67m7swU1tryQpbMKufzV5/OE68f4qXdbVy4sIZdzd1MK41y+Wm1bD3YwU9e2MsT21LLR3znow3c//Qb7Gru5j3nzObRrU1cc9YsKooKmF1ZxCWnTiOZhK88tIV51cUsq6silkjy29cO0VBfjWH0xZPsbe2hqriARTPKuP/pXTR29HHHyrOoLS/kjNseAmD9F66itz/Bj57fy0curqc3nqCjt5+uvgQzK4owS92I39vaQ1tPPy1dMWrLCqmrKeHVgx0k3Vl57hxea+xkx6EuPnXfc3zx2qVcf/48/u3JXbT2xLhowTTOm19F0uH2NRtZ8+I+blw+n7//vbNo7OjjgWd2c+25szPDft95Ygf3/GY7n7/6dK5/yzyKCkJ0xRI8s6OZ+5/ezbXnzOZdZ84C4PWmTjbvb+fiRdOYV13CvtYeKosLMIO+/iSHu2P0J5ye/gRLZ1fQ1RenqqSApKf2C+5ITxveuK+daaVR7nv6DWZVFHHN2bOYV11yXJ9RM3vW3RtGvZZDoL8fWOHuH08ffwi40N1vyirzSrrMnvTx6+kyI7e9T1Ogn1h2NXcxv6bkqD3DnliCzr545kbrb187xJ7D3axaPp+27n52H+7m5y/v54rTatm8v53Gjj7KCiNcsmgay+qqAPjl5kZuX7ORj122gJf2tNKfdD55xSK2NXby9I5migsiPL2jmY372gH4QMM8/viyBXzuwRd59WAHVSVR3nXmTC5ZNJ1z66p4eOMBfrWlkV3N3bzR0s2SWeWsOGsW58yr5NEtTTy/+zCn1palAzHEgumlmR9Et127lCWzy9nV3M0tWfP5S6JhQmZ09sUJGVSVRFleX8PjrzVRHA3TF0/SMWzZ48lWURQZsfTysagtL2RaaZQtBzrGLjzFouEQsawb97nK7iCELLWTWDy9cUx2Z6KiKEJ3LJG5NppwyJhRXnjUTsuAmRWFtPX0Ew2Hjvjf6JZrlvCJrH2Ij8UJE+hmthpYDTB//vzzd+3adVwNkvyXTDpNnX3MKC886g+ZY+HumBnuzt7WnhE9pN7+BP2J1LTNSChEyKA/4cQSScoKI/TFE4TM6OlP0NwZY39rD9WlUXYc6mJ3SzfXnDWbvniCU2eU8ejWRsqLCiiMhDh7biW7W3qIJZJsa+xkRkUhFUURthzo4Mw5lTyzo5m3LZlBUUGYXYe62dvaQyKZ6vUd6uxj4fRSLqivYffhbiA1FfUt86vp6O2nvKiAA229bNjVQmVxAYtqy9jX2kNvf5JN+9sojkaIhIyz51ZyoK2XsqIIB9p6eccZMyiJRnhqezPzqot56JUDlBVFiMWTqTCKhJhTWUxhJMTB9l4OdvRx1Rkz2bivjbLCCJXFBSyZXcGBth52NXdTP72U6pIoa1/en76PYiycXsamfW0UFoQpiYZp7owxvSxKd3+CaaVRDnXGKAgbVcVRZlcVEYsnKQiHeHlvG9NKo3T2xentT9DeG6ckGqYnluCC+hp6+hPsb+shHApRXVJATfoHU388SSQc4ty6VFs372+nujTKOXOreGZHM519CcoKw5xbV8WsyiLWvXIABw51xqgpLWBedQk9sQR98SSJZJLW7n7OmF3B/Gkl/Pyl/XT0pjozRQWp3zRLoxHqaoopCIdo7uyjvTeOO2w/1ElVcQGxRDKzReWSWeW83tRFbVmUs+ZWcs68qmMaLsv2ZgNdQy4iIieIowV6LvPQ1wOLzWyBmUWBVcCaYWXWAB9Jv34/8KujhbmIiIy/MWe5uHvczG4C1pGatvgdd99oZncAG9x9DfCvwL+Z2TaghVToi4jIJMppHrq7rwXWDjt3W9brXuCG8a2aiIgcCz36LyKSJxToIiJ5QoEuIpInFOgiInlCgS4ikifGfLBowr6xWRNwvI+KTgeOuKxAnsj3NuZ7+yD/25jv7YMTs42nuHvtaBemLNDfDDPbcKQnpfJFvrcx39sH+d/GfG8fBK+NGnIREckTCnQRkTwR1EC/Z6orMAnyvY353j7I/zbme/sgYG0M5Bi6iIiMFNQeuoiIDBO4QDezFWa21cy2mdnNU12f42Fm3zGzxvTGIAPnaszsF2b2WvrP6vR5M7P/nW7vS2b2lqmree7MrM7MHjWzTWa20cw+nT6fF+00syIze8bMXky378vp8wvM7Ol0O76fXnIaMytMH29LX6+f0gbkyMzCZva8mf0sfZxv7dtpZi+b2QtmtiF9LrCf0UAFetaG1dcAS4EbzWzp1NbquHwXWDHs3M3AI+6+GHgkfQypti5Of60Gvj1JdXyz4sDn3H0pcBHwqfR/q3xpZx/wdnc/F1gGrDCzi0htkP4Ndz8VOExqA3XI2kgd+Ea6XBB8GticdZxv7QN4m7svy5qeGNzPqLsH5gu4GFiXdXwLcMtU1+s421IPvJJ1vBWYnX49G9iafn03cONo5YL0BfwEeGc+thMoAZ4DLiT1EEokfT7zeSW1n8DF6deRdDmb6rqP0a55pALt7cDPAMun9qXruhOYPuxcYD+jgeqhA3OB3VnHe9Ln8sFMd9+ffn0AmJl+Hfg2p3/9Pg94mjxqZ3o44gWgEfgF8DrQ6u4DOwNntyHTvvT1NmDapFb42H0T+GtgYIfmaeRX+wAceNjMnk3veQwB/ozmtMGFTC53dzPLi+lHZlYG/D/gM+7enr3hc9Db6e4JYJmZVQE/ApZMbY3Gj5ldCzS6+7NmduUUV2ciXebue81sBvALM9uSfTFon9Gg9dD3AnVZx/PS5/LBQTObDZD+szF9PrBtNrMCUmF+n7v/MH0679rp7q3Ao6SGIKrSG6XD0DZk2pe+Xgk0T25Nj8mlwEoz2wk8QGrY5VvkT/sAcPe96T8bSf1QXk6AP6NBC/RcNqwOquyNtj9Casx54PyH03fYLwLasn4dPGFZqiv+r8Bmd/961qW8aKeZ1aZ75phZMan7A5tJBfv708WGty8wG6m7+y3uPs/d60n9f/Yrd/9D8qR9AGZWamblA6+Bq4FXCPJndKoH8Y/jJsa7gVdJjVd+Yarrc5xt+A9gP9BPahzuY6TGGx8BXgN+CdSkyxqpmT2vAy8DDVNd/xzbeBmp8cmXgBfSX+/Ol3YC5wDPp9v3CnBb+vxC4BlgG/CfQGH6fFH6eFv6+sKpbsMxtPVK4Gf51r50W15Mf20cyJMgf0b1pKiISJ4I2pCLiIgcgQJdRCRPKNBFRPKEAl1EJE8o0EVE8oQCXUQkTyjQRUTyhAJdRCRP/H+1BxpI3DHqUwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.trainer import Trainer\n",
    "from src.model import CNN_TC\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = CNN_TC('static', dataset, embed_mat, [3,4,5], 100, \\\n",
    "    dropout_ratio= .5, init=['he', None], bias=True, device=device).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=1 / torch.bincount(dataset['train_label']).to(torch.float).to(device))\n",
    "\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=1, rho=.95, weight_decay=1e-8)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=2e-6, weight_decay=.7)\n",
    "\n",
    "trainer = Trainer(model, criterion, optimizer, dataset, l2=9, device = device)\n",
    "\n",
    "## score= when l2=3\n",
    "trainer.train(30, show_batches=10)\n",
    "trainer.test()\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning CNN in \"SST1\" set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 40.63, Max : 45.11: 100%|██████████| 30/30 [08:08<00:00, 16.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for RAND was 45.11 at 2^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 41.49, Max : 46.29: 100%|██████████| 30/30 [04:00<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for STATIC was 46.29 at 7^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 40.68, Max : 48.87: 100%|██████████| 30/30 [08:07<00:00, 16.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for NONSTATIC was 48.87 at 2^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 43.44, Max : 48.19: 100%|██████████| 30/30 [11:11<00:00, 22.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for MULTICHANNEL was 48.19 at 0^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from src.model import CNN_TC\n",
    "from src.trainer import Trainer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda:0'\n",
    "option = ['rand', 'static', 'nonstatic', 'multichannel'] # 'rand',\n",
    "print(f\"Tuning CNN in \\\"{data.upper()}\\\" set.\")\n",
    "for opt in option:\n",
    "    \n",
    "    model = CNN_TC(opt, dataset, embed_mat, [3,4,5], 100, \\\n",
    "    dropout_ratio= .5, init=[None, 'he'], bias=True, device=device).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # weight=len(data['train_label']) / torch.bincount(data['train_label']).to(torch.float)\n",
    "\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=1, rho=.95, weight_decay=0)\n",
    "    trainer = Trainer(model, criterion, optimizer, dataset, l2=9, device=device)\n",
    "\n",
    "    lst = []\n",
    "    timeiter = tqdm(range(30), position=0, leave=True)\n",
    "    m = 0\n",
    "    for i in timeiter:\n",
    "        trainer.train(1, show_batches=50, verbose=False)\n",
    "        l = trainer.test(verbose=False)\n",
    "        lst.append(l)\n",
    "        m = max(m, l)\n",
    "        timeiter.set_description(f\"Acc : {100*l:.2f}, Max : {100*m:.2f}\")\n",
    "    #trainer.plot()\n",
    "    Len = np.argmax(lst)\n",
    "    print(f\"Best Score for {opt.upper()} was {100*m:.2f} at {Len}^th epoch\")\n",
    "# drop = .3\n",
    "## rho =.9  HN 92/89/90/90 NH 89/88/91/91\n",
    "## rho =.95 HN 91/88/91/89 NH 90/89/91/89\n",
    "# drop = .5\n",
    "## rho =.9  HN 91/88/90/89 NH 90/89/90/\n",
    "#### BH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ TEST Result\n",
    "\n",
    "|       Model|SST1 |SST2 | CR  | MR  |TREC|MPQA |SUBJ|\n",
    "|---         |---  |---  |---  |---  |--- |---  | ---|\n",
    "|Random      |45.11|84.84|79.89|75.26|91.6|85.49|90.7|\n",
    "|Static      |46.29|86.27|85.98|79.94|93.4|89.92|92.9|\n",
    "|Non-Static  |48.87|88.25|85.87|81.44|94.2|89.92|93.5|\n",
    "|MultiChannel|48.19|87.92|87.30|81.26|93.6|89.54|93.3|\n",
    "|Should Be...|46.??|87.??|83.??|80.??|92.?|88.??|91.?|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2695,  0.0859,  0.0942,  0.0410, -0.1836,  0.1289,  0.0625, -0.1006,\n",
       "         0.1484, -0.0659,  0.1367, -0.1904, -0.1226, -0.0591, -0.2949,  0.0850,\n",
       "        -0.0226,  0.2041, -0.0515, -0.0330, -0.0806,  0.0262,  0.0276,  0.1011,\n",
       "        -0.0171,  0.1069,  0.0732, -0.1143,  0.0211,  0.0618, -0.1104,  0.2930,\n",
       "        -0.0879, -0.1914,  0.0583,  0.1270,  0.2295,  0.0258,  0.0334,  0.0255,\n",
       "         0.0262,  0.0280,  0.0471, -0.0457, -0.0684,  0.0598, -0.0095,  0.0050,\n",
       "        -0.0144,  0.0830,  0.0625,  0.0396,  0.0352, -0.1768,  0.0830, -0.0674,\n",
       "        -0.1455,  0.0737,  0.1885,  0.0559,  0.0913,  0.0693, -0.1514, -0.0231,\n",
       "        -0.0728, -0.1846,  0.0620,  0.1250, -0.0106, -0.0204,  0.1260,  0.0996,\n",
       "         0.1670, -0.1621, -0.0043, -0.1416,  0.1572,  0.3887, -0.1299,  0.0703,\n",
       "        -0.0147, -0.0119, -0.0144, -0.1338, -0.2734, -0.2119, -0.2178,  0.2061,\n",
       "        -0.1270,  0.1758,  0.0364,  0.3301, -0.2061,  0.0884, -0.0312, -0.1387,\n",
       "         0.0378, -0.1216, -0.0187,  0.0104,  0.0466, -0.0126, -0.0518,  0.1025,\n",
       "        -0.1611, -0.0304, -0.3027, -0.0835,  0.0674,  0.0864,  0.0219, -0.0081,\n",
       "        -0.1104, -0.1299,  0.2344, -0.0104, -0.0049, -0.1719,  0.1187,  0.0728,\n",
       "        -0.4160,  0.0767,  0.0359, -0.0208,  0.0540,  0.1631, -0.3125,  0.1216,\n",
       "        -0.0396, -0.1050, -0.1187, -0.0972, -0.1592, -0.1689, -0.0583, -0.1445,\n",
       "         0.0923, -0.1250, -0.0361,  0.0718,  0.2324,  0.0103, -0.0928, -0.0253,\n",
       "         0.1719, -0.0364,  0.0157, -0.3145,  0.0225,  0.0544,  0.0161,  0.1719,\n",
       "        -0.3047,  0.0297,  0.0562,  0.0601, -0.0256, -0.1562, -0.0281,  0.0698,\n",
       "         0.0608,  0.3555,  0.0236,  0.0248, -0.0674, -0.0801,  0.0021, -0.1279,\n",
       "         0.0674,  0.0505, -0.1074,  0.1250, -0.1021, -0.0369,  0.0840,  0.0977,\n",
       "         0.1211, -0.0757, -0.0378, -0.0281, -0.1494, -0.0762,  0.0269, -0.1787,\n",
       "         0.1016, -0.0903, -0.1406,  0.0864, -0.0028,  0.0115,  0.2637,  0.0021,\n",
       "         0.0532, -0.1680,  0.0223, -0.0996,  0.0417, -0.0811,  0.1113, -0.2090,\n",
       "        -0.0483,  0.1108, -0.1650,  0.2178,  0.0649, -0.1235, -0.0510, -0.0121,\n",
       "        -0.0320, -0.0728, -0.0815,  0.0012,  0.0396, -0.0593, -0.1719,  0.0520,\n",
       "         0.2158,  0.2422,  0.0669,  0.1885, -0.0811,  0.0884, -0.0669, -0.1167,\n",
       "         0.0024, -0.1074,  0.1187, -0.1504,  0.0669, -0.0498,  0.1475, -0.1069,\n",
       "         0.0131, -0.1934,  0.1001, -0.3320, -0.0388,  0.0173,  0.0457, -0.0422,\n",
       "        -0.0811, -0.0474,  0.0879, -0.1562, -0.2100, -0.0466,  0.0120, -0.0408,\n",
       "        -0.0177,  0.0854,  0.0240,  0.3047,  0.3398,  0.0430,  0.1943, -0.1963,\n",
       "         0.2070,  0.0043, -0.2012, -0.0747, -0.0479,  0.0339, -0.2275,  0.0400,\n",
       "        -0.1914,  0.0801,  0.2188, -0.0376, -0.0297,  0.0781,  0.0698,  0.0320,\n",
       "         0.1631,  0.2676, -0.0825, -0.1152, -0.0034, -0.0659, -0.0359,  0.0850,\n",
       "         0.1650,  0.1128, -0.0233,  0.2314, -0.0527, -0.3301, -0.1387,  0.0007,\n",
       "         0.0869,  0.3223, -0.2236, -0.1504, -0.0962, -0.1992, -0.1904, -0.0067,\n",
       "         0.1104,  0.1230, -0.0184, -0.1670], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding[1].weight[dataset['w2i'][wrd]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getvect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/hdd1/user6/Public/freshman/CNN/Untitle.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.96/hdd1/user6/Public/freshman/CNN/Untitle.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#getvect = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.96/hdd1/user6/Public/freshman/CNN/Untitle.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.96/hdd1/user6/Public/freshman/CNN/Untitle.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#model0 = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.96/hdd1/user6/Public/freshman/CNN/Untitle.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m wrd \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhow\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.96/hdd1/user6/Public/freshman/CNN/Untitle.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(getvect\u001b[39m.\u001b[39mget_vector(wrd))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getvect' is not defined"
     ]
    }
   ],
   "source": [
    "#getvect = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "#model0 = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "wrd = 'how'\n",
    "np.linalg.norm(getvect.get_vector(wrd))\n",
    "#sum(getvect.get_vector(wrd) == model.embedding[1].weight[dataset['w2i'][wrd]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "training mode is expected to be boolean",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/hdd1/user6/Public/freshman/CNN/Untitle.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.23.96/hdd1/user6/Public/freshman/CNN/Untitle.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m:\u001b[39m5\u001b[39;49m])\n",
      "File \u001b[0;32m~/.conda/envs/freshman01/lib/python3.10/site-packages/torch/nn/modules/module.py:1836\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sets the module in training mode.\u001b[39;00m\n\u001b[1;32m   1822\u001b[0m \n\u001b[1;32m   1823\u001b[0m \u001b[39mThis has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[39m    Module: self\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1835\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mode, \u001b[39mbool\u001b[39m):\n\u001b[0;32m-> 1836\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtraining mode is expected to be boolean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1837\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n",
      "\u001b[0;31mValueError\u001b[0m: training mode is expected to be boolean"
     ]
    }
   ],
   "source": [
    "model.train(dataset['train'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.tensor(model.get_vector('donto')).to(torch.float)\n",
    "\n",
    "model.has_index_for(\"do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PADDING]': 0,\n",
       " 'simplistic': 1,\n",
       " ',': 2,\n",
       " 'silly': 3,\n",
       " 'and': 4,\n",
       " 'tedious': 5,\n",
       " 'it': 6,\n",
       " \"'s\": 7,\n",
       " 'so': 8,\n",
       " 'laddish': 9,\n",
       " 'juvenile': 10,\n",
       " 'only': 11,\n",
       " 'teenage': 12,\n",
       " 'boys': 13,\n",
       " 'could': 14,\n",
       " 'possibly': 15,\n",
       " 'find': 16,\n",
       " 'funny': 17,\n",
       " 'exploitative': 18,\n",
       " 'largely': 19,\n",
       " 'devoid': 20,\n",
       " 'of': 21,\n",
       " 'the': 22,\n",
       " 'depth': 23,\n",
       " 'or': 24,\n",
       " 'sophistication': 25,\n",
       " 'that': 26,\n",
       " 'would': 27,\n",
       " 'make': 28,\n",
       " 'watching': 29,\n",
       " 'such': 30,\n",
       " 'a': 31,\n",
       " 'graphic': 32,\n",
       " 'treatment': 33,\n",
       " 'crimes': 34,\n",
       " 'bearable': 35,\n",
       " 'garbus': 36,\n",
       " 'discards': 37,\n",
       " 'potential': 38,\n",
       " 'for': 39,\n",
       " 'pathological': 40,\n",
       " 'study': 41,\n",
       " 'exhuming': 42,\n",
       " 'instead': 43,\n",
       " 'skewed': 44,\n",
       " 'melodrama': 45,\n",
       " 'circumstantial': 46,\n",
       " 'situation': 47,\n",
       " 'visually': 48,\n",
       " 'flashy': 49,\n",
       " 'but': 50,\n",
       " 'narratively': 51,\n",
       " 'opaque': 52,\n",
       " 'emotionally': 53,\n",
       " 'vapid': 54,\n",
       " 'exercise': 55,\n",
       " 'in': 56,\n",
       " 'style': 57,\n",
       " 'mystification': 58,\n",
       " 'story': 59,\n",
       " 'is': 60,\n",
       " 'also': 61,\n",
       " 'as': 62,\n",
       " 'unoriginal': 63,\n",
       " 'they': 64,\n",
       " 'come': 65,\n",
       " 'already': 66,\n",
       " 'having': 67,\n",
       " 'been': 68,\n",
       " 'recycled': 69,\n",
       " 'more': 70,\n",
       " 'times': 71,\n",
       " 'than': 72,\n",
       " 'i': 73,\n",
       " \"'d\": 74,\n",
       " 'care': 75,\n",
       " 'to': 76,\n",
       " 'count': 77,\n",
       " 'about': 78,\n",
       " 'thing': 79,\n",
       " 'give': 80,\n",
       " 'movie': 81,\n",
       " 'points': 82,\n",
       " 'bravado': 83,\n",
       " 'take': 84,\n",
       " 'an': 85,\n",
       " 'entirely': 86,\n",
       " 'stale': 87,\n",
       " 'concept': 88,\n",
       " 'push': 89,\n",
       " 'through': 90,\n",
       " 'audience': 91,\n",
       " 'meat': 92,\n",
       " 'grinder': 93,\n",
       " 'one': 94,\n",
       " 'time': 95,\n",
       " 'not': 96,\n",
       " 'much': 97,\n",
       " 'farcical': 98,\n",
       " 'sour': 99,\n",
       " 'unfortunately': 100,\n",
       " 'actors': 101,\n",
       " 'are': 102,\n",
       " 'served': 103,\n",
       " 'with': 104,\n",
       " 'hack': 105,\n",
       " 'script': 106,\n",
       " 'all': 107,\n",
       " 'disquieting': 108,\n",
       " 'its': 109,\n",
       " 'relatively': 110,\n",
       " 'gore': 111,\n",
       " 'free': 112,\n",
       " 'allusions': 113,\n",
       " 'serial': 114,\n",
       " 'murders': 115,\n",
       " 'falls': 116,\n",
       " 'down': 117,\n",
       " 'attempts': 118,\n",
       " 'humanize': 119,\n",
       " 'subject': 120,\n",
       " 'sentimental': 121,\n",
       " 'mess': 122,\n",
       " 'never': 123,\n",
       " 'rings': 124,\n",
       " 'true': 125,\n",
       " 'while': 126,\n",
       " 'performances': 127,\n",
       " 'often': 128,\n",
       " 'engaging': 129,\n",
       " 'this': 130,\n",
       " 'loose': 131,\n",
       " 'collection': 132,\n",
       " 'improvised': 133,\n",
       " 'numbers': 134,\n",
       " 'probably': 135,\n",
       " 'have': 136,\n",
       " 'worked': 137,\n",
       " 'better': 138,\n",
       " 'hour': 139,\n",
       " 'tv': 140,\n",
       " 'documentary': 141,\n",
       " 'interesting': 142,\n",
       " 'compelling': 143,\n",
       " 'on': 144,\n",
       " 'cutting': 145,\n",
       " 'room': 146,\n",
       " 'floor': 147,\n",
       " 'somewhere': 148,\n",
       " 'lies': 149,\n",
       " 'footage': 150,\n",
       " 'might': 151,\n",
       " 'made': 152,\n",
       " 'no': 153,\n",
       " 'trenchant': 154,\n",
       " 'ironic': 155,\n",
       " 'cultural': 156,\n",
       " 'satire': 157,\n",
       " 'frustrating': 158,\n",
       " 'misfire': 159,\n",
       " 'ensemble': 160,\n",
       " 'player': 161,\n",
       " 'who': 162,\n",
       " 'gained': 163,\n",
       " 'notice': 164,\n",
       " 'guy': 165,\n",
       " 'ritchie': 166,\n",
       " 'lock': 167,\n",
       " 'stock': 168,\n",
       " 'two': 169,\n",
       " 'smoking': 170,\n",
       " 'barrels': 171,\n",
       " 'snatch': 172,\n",
       " 'has': 173,\n",
       " 'bod': 174,\n",
       " 'he': 175,\n",
       " 'unlikely': 176,\n",
       " 'become': 177,\n",
       " 'household': 178,\n",
       " 'name': 179,\n",
       " 'basis': 180,\n",
       " 'his': 181,\n",
       " 'first': 182,\n",
       " 'starring': 183,\n",
       " 'vehicle': 184,\n",
       " 'there': 185,\n",
       " 'difference': 186,\n",
       " 'between': 187,\n",
       " 'movies': 188,\n",
       " 'courage': 189,\n",
       " 'go': 190,\n",
       " 'over': 191,\n",
       " 'top': 192,\n",
       " 'do': 193,\n",
       " \"n't\": 194,\n",
       " 'being': 195,\n",
       " 'stupid': 196,\n",
       " 'nothing': 197,\n",
       " 'here': 198,\n",
       " 'seems': 199,\n",
       " 'did': 200,\n",
       " 'analyze': 201,\n",
       " 'even': 202,\n",
       " 'joe': 203,\n",
       " 'viterelli': 204,\n",
       " 'de': 205,\n",
       " 'niro': 206,\n",
       " 'right': 207,\n",
       " 'hand': 208,\n",
       " 'goombah': 209,\n",
       " 'master': 210,\n",
       " 'screenwriting': 211,\n",
       " 'comes': 212,\n",
       " 'courtesy': 213,\n",
       " 'john': 214,\n",
       " 'pogue': 215,\n",
       " 'yale': 216,\n",
       " 'grad': 217,\n",
       " 'previously': 218,\n",
       " 'gave': 219,\n",
       " 'us': 220,\n",
       " 'skulls': 221,\n",
       " 'last': 222,\n",
       " 'year': 223,\n",
       " 'rollerball': 224,\n",
       " 'enough': 225,\n",
       " 'said': 226,\n",
       " 'except': 227,\n",
       " 'film': 228,\n",
       " 'overboard': 229,\n",
       " '!': 230,\n",
       " 'common': 231,\n",
       " 'sense': 232,\n",
       " 'flies': 233,\n",
       " 'out': 234,\n",
       " 'window': 235,\n",
       " 'along': 236,\n",
       " 'hail': 237,\n",
       " 'bullets': 238,\n",
       " 'none': 239,\n",
       " 'which': 240,\n",
       " 'ever': 241,\n",
       " 'seem': 242,\n",
       " 'hit': 243,\n",
       " 'sascha': 244,\n",
       " '100': 245,\n",
       " 'minute': 246,\n",
       " '25': 247,\n",
       " 'minutes': 248,\n",
       " 'decent': 249,\n",
       " 'material': 250,\n",
       " 'execution': 251,\n",
       " 'pedestrian': 252,\n",
       " 'most': 253,\n",
       " 'positive': 254,\n",
       " 'comment': 255,\n",
       " 'we': 256,\n",
       " 'can': 257,\n",
       " 'rob': 258,\n",
       " 'schneider': 259,\n",
       " 'actually': 260,\n",
       " 'turns': 261,\n",
       " 'pretty': 262,\n",
       " 'convincing': 263,\n",
       " 'performance': 264,\n",
       " 'prissy': 265,\n",
       " 'girl': 266,\n",
       " 'own': 267,\n",
       " 'very': 268,\n",
       " 'remake': 269,\n",
       " 'pale': 270,\n",
       " 'imitation': 271,\n",
       " 'shows': 272,\n",
       " 'some': 273,\n",
       " 'studios': 274,\n",
       " 'firmly': 275,\n",
       " 'believe': 276,\n",
       " 'people': 277,\n",
       " 'lost': 278,\n",
       " 'ability': 279,\n",
       " 'think': 280,\n",
       " 'will': 281,\n",
       " 'forgive': 282,\n",
       " 'any': 283,\n",
       " 'shoddy': 284,\n",
       " 'product': 285,\n",
       " 'long': 286,\n",
       " 'little': 287,\n",
       " 'action': 288,\n",
       " 'farce': 289,\n",
       " 'parody': 290,\n",
       " 'comedy': 291,\n",
       " 'premise': 292,\n",
       " 'comparison': 293,\n",
       " 'reality': 294,\n",
       " 'commentary': 295,\n",
       " 'our': 296,\n",
       " 'knowledge': 297,\n",
       " 'films': 298,\n",
       " 'exciting': 299,\n",
       " 'exoticism': 300,\n",
       " 'sound': 301,\n",
       " 'typical': 302,\n",
       " 'pax': 303,\n",
       " 'viewer': 304,\n",
       " 'rest': 305,\n",
       " 'be': 306,\n",
       " 'lulled': 307,\n",
       " 'into': 308,\n",
       " 'coma': 309,\n",
       " 'party': 310,\n",
       " 'scenes': 311,\n",
       " 'deliver': 312,\n",
       " 'tawdry': 313,\n",
       " 'kicks': 314,\n",
       " 'dudsville': 315,\n",
       " 'culture': 316,\n",
       " 'headed': 317,\n",
       " 'toilet': 318,\n",
       " 'ferocity': 319,\n",
       " 'frozen': 320,\n",
       " 'burrito': 321,\n",
       " 'after': 322,\n",
       " 'night': 323,\n",
       " 'tequila': 324,\n",
       " 'bender': 325,\n",
       " 'know': 326,\n",
       " 'because': 327,\n",
       " \"'ve\": 328,\n",
       " 'seen': 329,\n",
       " \"'jackass\": 330,\n",
       " \"'\": 331,\n",
       " 'criticism': 332,\n",
       " 'rises': 333,\n",
       " 'above': 334,\n",
       " 'easy': 335,\n",
       " 'cynical': 336,\n",
       " 'potshots': 337,\n",
       " 'at': 338,\n",
       " 'morally': 339,\n",
       " 'bankrupt': 340,\n",
       " 'characters': 341,\n",
       " 'something': 342,\n",
       " 'borrowed': 343,\n",
       " 'construction': 344,\n",
       " 'feels': 345,\n",
       " 'less': 346,\n",
       " 'loving': 347,\n",
       " 'well': 348,\n",
       " 'integrated': 349,\n",
       " 'homage': 350,\n",
       " 'like': 351,\n",
       " 'mere': 352,\n",
       " 'excuse': 353,\n",
       " 'wan': 354,\n",
       " 'thinly': 355,\n",
       " 'sketched': 356,\n",
       " 'killing': 357,\n",
       " 'going': 358,\n",
       " 'infantile': 359,\n",
       " 'redundant': 360,\n",
       " 'sloppy': 361,\n",
       " 'amateurish': 362,\n",
       " 'yep': 363,\n",
       " 'waking': 364,\n",
       " 'up': 365,\n",
       " 'reno': 366,\n",
       " 'back': 367,\n",
       " 'sleep': 368,\n",
       " 'middle': 369,\n",
       " 'compels': 370,\n",
       " 'demme': 371,\n",
       " 'experiments': 372,\n",
       " 'harvests': 373,\n",
       " 'few': 374,\n",
       " 'moment': 375,\n",
       " 'gems': 376,\n",
       " 'field': 377,\n",
       " 'roughage': 378,\n",
       " 'dominates': 379,\n",
       " 'clich': 380,\n",
       " 's': 381,\n",
       " 'just': 382,\n",
       " 'pile': 383,\n",
       " 'payami': 384,\n",
       " 'tries': 385,\n",
       " 'raise': 386,\n",
       " 'serious': 387,\n",
       " 'issues': 388,\n",
       " 'iran': 389,\n",
       " 'electoral': 390,\n",
       " 'process': 391,\n",
       " 'result': 392,\n",
       " 'subtle': 393,\n",
       " 'political': 394,\n",
       " 'broadcast': 395,\n",
       " 'surprise': 396,\n",
       " 'heavyweights': 397,\n",
       " 'joel': 398,\n",
       " 'silver': 399,\n",
       " 'robert': 400,\n",
       " 'zemeckis': 401,\n",
       " 'agreed': 402,\n",
       " 'produce': 403,\n",
       " 'assume': 404,\n",
       " 'director': 405,\n",
       " 'pictures': 406,\n",
       " 'them': 407,\n",
       " 'cavorting': 408,\n",
       " \"ladies'\": 409,\n",
       " 'underwear': 410,\n",
       " 'another': 411,\n",
       " 'useless': 412,\n",
       " 'recycling': 413,\n",
       " 'brutal': 414,\n",
       " 'mid': 415,\n",
       " \"'70s\": 416,\n",
       " 'american': 417,\n",
       " 'sports': 418,\n",
       " 'laugh': 419,\n",
       " 'smile': 420,\n",
       " 'survived': 421,\n",
       " 'please': 422,\n",
       " 'someone': 423,\n",
       " 'stop': 424,\n",
       " 'eric': 425,\n",
       " 'schaeffer': 426,\n",
       " 'before': 427,\n",
       " 'makes': 428,\n",
       " 'problems': 429,\n",
       " 'derive': 430,\n",
       " 'from': 431,\n",
       " 'screenplay': 432,\n",
       " 'rather': 433,\n",
       " 'mediocre': 434,\n",
       " 'by': 435,\n",
       " 'involved': 436,\n",
       " 'if': 437,\n",
       " 'you': 438,\n",
       " \"'re\": 439,\n",
       " 'mood': 440,\n",
       " 'fun': 441,\n",
       " 'bad': 442,\n",
       " 'want': 443,\n",
       " 'catch': 444,\n",
       " 'freaks': 445,\n",
       " 'matinee': 446,\n",
       " 'curling': 447,\n",
       " 'may': 448,\n",
       " 'unique': 449,\n",
       " 'sport': 450,\n",
       " 'men': 451,\n",
       " 'brooms': 452,\n",
       " 'distinctly': 453,\n",
       " 'ordinary': 454,\n",
       " 'though': 455,\n",
       " 'opera': 456,\n",
       " 'itself': 457,\n",
       " 'takes': 458,\n",
       " 'place': 459,\n",
       " 'mostly': 460,\n",
       " 'indoors': 461,\n",
       " 'jacquot': 462,\n",
       " 'unsure': 463,\n",
       " 'how': 464,\n",
       " 'evoke': 465,\n",
       " 'sort': 466,\n",
       " 'naturalism': 467,\n",
       " 'set': 468,\n",
       " 'getting': 469,\n",
       " 'around': 470,\n",
       " 'fact': 471,\n",
       " 'revenge': 472,\n",
       " 'nerds': 473,\n",
       " 'revisited': 474,\n",
       " 'again': 475,\n",
       " 'effort': 476,\n",
       " 'sincere': 477,\n",
       " 'results': 478,\n",
       " 'honest': 479,\n",
       " 'bleak': 480,\n",
       " 'hardly': 481,\n",
       " 'watchable': 482,\n",
       " 'regurgitates': 483,\n",
       " 'waters': 484,\n",
       " 'many': 485,\n",
       " 'previous': 486,\n",
       " 'successes': 487,\n",
       " 'new': 488,\n",
       " 'swings': 489,\n",
       " 'thrown': 490,\n",
       " 'flashbulb': 491,\n",
       " 'editing': 492,\n",
       " 'cover': 493,\n",
       " 'absence': 494,\n",
       " 'narrative': 495,\n",
       " 'continuity': 496,\n",
       " 'undisputed': 497,\n",
       " 'nearly': 498,\n",
       " 'incoherent': 499,\n",
       " 'get': 500,\n",
       " 'closing': 501,\n",
       " 'bout': 502,\n",
       " 'impossible': 503,\n",
       " 'wins': 504,\n",
       " 'stinks': 505,\n",
       " 'start': 506,\n",
       " 'finish': 507,\n",
       " 'wet': 508,\n",
       " 'burlap': 509,\n",
       " 'sack': 510,\n",
       " 'gloom': 511,\n",
       " 'civilized': 512,\n",
       " 'mind': 513,\n",
       " 'ballistic': 514,\n",
       " 'ecks': 515,\n",
       " 'vs': 516,\n",
       " 'sever': 517,\n",
       " 'ordeal': 518,\n",
       " 'amusement': 519,\n",
       " 'equlibrium': 520,\n",
       " 'pass': 521,\n",
       " 'thirteen': 522,\n",
       " 'old': 523,\n",
       " 'book': 524,\n",
       " 'report': 525,\n",
       " 'totalitarian': 526,\n",
       " 'themes': 527,\n",
       " '1984': 528,\n",
       " 'farenheit': 529,\n",
       " '451': 530,\n",
       " 'lack': 531,\n",
       " 'naturalness': 532,\n",
       " 'everything': 533,\n",
       " 'self': 534,\n",
       " 'consciously': 535,\n",
       " 'poetic': 536,\n",
       " 'forced': 537,\n",
       " 'pity': 538,\n",
       " 'nelson': 539,\n",
       " 'achievement': 540,\n",
       " 'does': 541,\n",
       " 'match': 542,\n",
       " 'ambition': 543,\n",
       " 'off': 544,\n",
       " 'when': 545,\n",
       " 'seagal': 546,\n",
       " 'appeared': 547,\n",
       " 'orange': 548,\n",
       " 'prison': 549,\n",
       " 'jumpsuit': 550,\n",
       " 'wanted': 551,\n",
       " 'stand': 552,\n",
       " 'theater': 553,\n",
       " 'shout': 554,\n",
       " \"'hey\": 555,\n",
       " 'kool': 556,\n",
       " 'aid': 557,\n",
       " 'watch': 558,\n",
       " 'annoying': 559,\n",
       " 'demeanour': 560,\n",
       " 'lead': 561,\n",
       " 'character': 562,\n",
       " 'imagine': 563,\n",
       " 'cleanflicks': 564,\n",
       " 'version': 565,\n",
       " \"'love\": 566,\n",
       " 'ali': 567,\n",
       " 'macgraw': 568,\n",
       " 'profanities': 569,\n",
       " 'replaced': 570,\n",
       " 'romance': 571,\n",
       " 'novel': 572,\n",
       " 'platitudes': 573,\n",
       " 'pc': 574,\n",
       " 'stability': 575,\n",
       " 'notwithstanding': 576,\n",
       " 'suffers': 577,\n",
       " 'pat': 578,\n",
       " 'fairy': 579,\n",
       " 'tale': 580,\n",
       " 'conclusion': 581,\n",
       " 'forget': 582,\n",
       " 'misleading': 583,\n",
       " 'title': 584,\n",
       " 'what': 585,\n",
       " 'unexplained': 586,\n",
       " 'baboon': 587,\n",
       " 'cameo': 588,\n",
       " '?': 589,\n",
       " 'odd': 590,\n",
       " 'haphazard': 591,\n",
       " 'inconsequential': 592,\n",
       " 'romantic': 593,\n",
       " 'her': 594,\n",
       " 'fans': 595,\n",
       " 'assuredly': 596,\n",
       " 'their': 597,\n",
       " 'bones': 598,\n",
       " 'tickled': 599,\n",
       " 'others': 600,\n",
       " 'humor': 601,\n",
       " 'seeking': 602,\n",
       " 'dollars': 603,\n",
       " 'best': 604,\n",
       " 'spent': 605,\n",
       " 'elsewhere': 606,\n",
       " 'pascale': 607,\n",
       " 'bailly': 608,\n",
       " 'rom': 609,\n",
       " 'com': 610,\n",
       " 'provides': 611,\n",
       " 'am': 612,\n",
       " 'lie': 613,\n",
       " 'audrey': 614,\n",
       " 'tautou': 615,\n",
       " 'fabuleux': 616,\n",
       " 'destin': 617,\n",
       " 'e': 618,\n",
       " 'banal': 619,\n",
       " 'spiritual': 620,\n",
       " 'quest': 621,\n",
       " 'static': 622,\n",
       " 'sugary': 623,\n",
       " 'half': 624,\n",
       " 'school': 625,\n",
       " 'special': 626,\n",
       " 'interfaith': 627,\n",
       " 'understanding': 628,\n",
       " 'stretched': 629,\n",
       " '90': 630,\n",
       " 'chemistry': 631,\n",
       " 'freeman': 632,\n",
       " 'judd': 633,\n",
       " 'however': 634,\n",
       " 'almost': 635,\n",
       " 'worth': 636,\n",
       " 'seeing': 637,\n",
       " 'pretentious': 638,\n",
       " 'ultimately': 639,\n",
       " 'empty': 640,\n",
       " 'examination': 641,\n",
       " 'sick': 642,\n",
       " 'evil': 643,\n",
       " 'woman': 644,\n",
       " 'country': 645,\n",
       " 'bears': 646,\n",
       " 'upset': 647,\n",
       " 'frighten': 648,\n",
       " 'young': 649,\n",
       " 'viewers': 650,\n",
       " 'flat': 651,\n",
       " 'amuse': 652,\n",
       " 'entertain': 653,\n",
       " 'either': 654,\n",
       " 'cumulative': 655,\n",
       " 'effect': 656,\n",
       " '65': 657,\n",
       " 'trifle': 658,\n",
       " 'trapped': 659,\n",
       " 'weird': 660,\n",
       " 'relative': 661,\n",
       " 'trots': 662,\n",
       " 'video': 663,\n",
       " 'took': 664,\n",
       " 'family': 665,\n",
       " 'vacation': 666,\n",
       " 'stonehenge': 667,\n",
       " 'desperate': 668,\n",
       " 'evening': 669,\n",
       " 'end': 670,\n",
       " 'sketches': 671,\n",
       " 'leaves': 672,\n",
       " 'emotional': 673,\n",
       " 'connection': 674,\n",
       " 'identification': 675,\n",
       " 'frustratingly': 676,\n",
       " 'reach': 677,\n",
       " 'mattei': 678,\n",
       " 'underdeveloped': 679,\n",
       " 'convenient': 680,\n",
       " 'conveyor': 681,\n",
       " 'belt': 682,\n",
       " 'brooding': 683,\n",
       " 'personalities': 684,\n",
       " 'parade': 685,\n",
       " 'were': 686,\n",
       " 'coming': 687,\n",
       " 'camp': 688,\n",
       " 'drowsy': 689,\n",
       " 'drama': 690,\n",
       " 'infatuated': 691,\n",
       " 'final': 692,\n",
       " 'surprising': 693,\n",
       " 'shots': 694,\n",
       " 'rabbit': 695,\n",
       " 'proof': 696,\n",
       " 'fence': 697,\n",
       " 'authority': 698,\n",
       " 'looking': 699,\n",
       " 'sharp': 700,\n",
       " 'original': 701,\n",
       " 'despite': 702,\n",
       " 'visual': 703,\n",
       " 'virtues': 704,\n",
       " \"'blade\": 705,\n",
       " \"ii'\": 706,\n",
       " 'cut': 707,\n",
       " 'plays': 708,\n",
       " 'badly': 709,\n",
       " 'edited': 710,\n",
       " '91': 711,\n",
       " 'trailer': 712,\n",
       " '(': 713,\n",
       " ')': 714,\n",
       " 'ca': 715,\n",
       " 'coherent': 716,\n",
       " 'rhythm': 717,\n",
       " 'she': 718,\n",
       " 'tried': 719,\n",
       " 'maybe': 720,\n",
       " 'leblanc': 721,\n",
       " 'thought': 722,\n",
       " 'hey': 723,\n",
       " 'baseball': 724,\n",
       " 'playing': 725,\n",
       " 'monkey': 726,\n",
       " 'was': 727,\n",
       " 'worse': 728,\n",
       " 'expect': 729,\n",
       " 'assuming': 730,\n",
       " 'bar': 731,\n",
       " 'expectations': 732,\n",
       " 'raised': 733,\n",
       " 'sixth': 734,\n",
       " 'grade': 735,\n",
       " 'height': 736,\n",
       " 'barry': 737,\n",
       " 'sonnenfeld': 738,\n",
       " 'owes': 739,\n",
       " 'frank': 740,\n",
       " 'pug': 741,\n",
       " 'big': 742,\n",
       " 'biggest': 743,\n",
       " 'problem': 744,\n",
       " 'roger': 745,\n",
       " 'avary': 746,\n",
       " 'uproar': 747,\n",
       " 'against': 748,\n",
       " 'mpaa': 749,\n",
       " 'glory': 750,\n",
       " 'barely': 751,\n",
       " 'shocking': 752,\n",
       " 'anything': 753,\n",
       " 'riddled': 754,\n",
       " 'unanswered': 755,\n",
       " 'questions': 756,\n",
       " 'requires': 757,\n",
       " 'gargantuan': 758,\n",
       " 'leaps': 759,\n",
       " 'faith': 760,\n",
       " 'plod': 761,\n",
       " 'approached': 762,\n",
       " 'usher': 763,\n",
       " 'had': 764,\n",
       " 'sit': 765,\n",
       " 'should': 766,\n",
       " 'ask': 767,\n",
       " 'earnest': 768,\n",
       " 'heavy': 769,\n",
       " 'handed': 770,\n",
       " 'sinise': 771,\n",
       " 'brain': 772,\n",
       " 'five': 773,\n",
       " 'plot': 774,\n",
       " 'goes': 775,\n",
       " 'way': 776,\n",
       " 'introduce': 777,\n",
       " 'obstacles': 778,\n",
       " 'him': 779,\n",
       " 'stumble': 780,\n",
       " 'too': 781,\n",
       " 'slow': 782,\n",
       " 'younger': 783,\n",
       " 'crowd': 784,\n",
       " 'shallow': 785,\n",
       " 'older': 786,\n",
       " 'reason': 787,\n",
       " 'studio': 788,\n",
       " 'offer': 789,\n",
       " 'advance': 790,\n",
       " 'screening': 791,\n",
       " 'adventures': 792,\n",
       " 'pluto': 793,\n",
       " 'nash': 794,\n",
       " 'stinker': 795,\n",
       " 'punch': 796,\n",
       " 'line': 797,\n",
       " 'without': 798,\n",
       " 'joke': 799,\n",
       " 'built': 800,\n",
       " 'musty': 801,\n",
       " 'memories': 802,\n",
       " 'dimensional': 803,\n",
       " 'puts': 804,\n",
       " 'battle': 805,\n",
       " 'wills': 806,\n",
       " 'things': 807,\n",
       " 'buy': 808,\n",
       " 'wo': 809,\n",
       " 'fly': 810,\n",
       " 'intelligent': 811,\n",
       " 'enticing': 812,\n",
       " 'prospect': 813,\n",
       " 'lot': 814,\n",
       " 'nubile': 815,\n",
       " 'campus': 816,\n",
       " 'depravity': 817,\n",
       " 'fade': 818,\n",
       " 'amid': 819,\n",
       " 'deliberate': 820,\n",
       " 'tiresome': 821,\n",
       " 'ugliness': 822,\n",
       " 'rendered': 823,\n",
       " 'failure': 824,\n",
       " 'construct': 825,\n",
       " 'trace': 826,\n",
       " 'dramatic': 827,\n",
       " 'interest': 828,\n",
       " 'sitting': 829,\n",
       " 'reel': 830,\n",
       " 'spoiler': 831,\n",
       " 'alert': 832,\n",
       " 'significantly': 833,\n",
       " 'charming': 834,\n",
       " 'listening': 835,\n",
       " 'four': 836,\n",
       " 'taste': 837,\n",
       " 'exaggeration': 838,\n",
       " 'recount': 839,\n",
       " 'halloween': 840,\n",
       " 'trip': 841,\n",
       " 'haunted': 842,\n",
       " 'house': 843,\n",
       " 'confuses': 844,\n",
       " 'message': 845,\n",
       " 'ultimate': 846,\n",
       " 'desire': 847,\n",
       " 'contorting': 848,\n",
       " 'idea': 849,\n",
       " 'expectation': 850,\n",
       " 'these': 851,\n",
       " 'three': 852,\n",
       " 'actresses': 853,\n",
       " 'nor': 854,\n",
       " 'deserve': 855,\n",
       " 'deadly': 856,\n",
       " 'dull': 857,\n",
       " 'pointless': 858,\n",
       " 'meditation': 859,\n",
       " 'losers': 860,\n",
       " 'gone': 861,\n",
       " 'seed': 862,\n",
       " 'hotel': 863,\n",
       " 'sensibility': 864,\n",
       " 'overrun': 865,\n",
       " 'characterized': 866,\n",
       " 'robotic': 867,\n",
       " 'sentiment': 868,\n",
       " 'jury': 869,\n",
       " 'bestowed': 870,\n",
       " 'star': 871,\n",
       " 'hoffman': 872,\n",
       " 'brother': 873,\n",
       " 'gordy': 874,\n",
       " 'waldo': 875,\n",
       " 'salt': 876,\n",
       " 'award': 877,\n",
       " '2002': 878,\n",
       " 'sundance': 879,\n",
       " 'festival': 880,\n",
       " 'honoring': 881,\n",
       " 'attempt': 882,\n",
       " 'different': 883,\n",
       " 'pulling': 884,\n",
       " 'prescribed': 885,\n",
       " 'recommended': 886,\n",
       " 'bland': 887,\n",
       " 'dentist': 888,\n",
       " 'waiting': 889,\n",
       " 'complete': 890,\n",
       " 'soothing': 891,\n",
       " 'muzak': 892,\n",
       " 'cushion': 893,\n",
       " 'predictable': 894,\n",
       " 'rhythms': 895,\n",
       " 'sex': 896,\n",
       " 'ironically': 897,\n",
       " 'becomes': 898,\n",
       " 'lame': 899,\n",
       " 'try': 900,\n",
       " 'evade': 901,\n",
       " 'your': 902,\n",
       " 'responsibilities': 903,\n",
       " 'leave': 904,\n",
       " 'large': 905,\n",
       " 'dog': 906,\n",
       " 'alone': 907,\n",
       " 'toddler': 908,\n",
       " 'boobs': 909,\n",
       " 'fantasti': 910,\n",
       " 'covers': 911,\n",
       " 'huge': 912,\n",
       " 'topics': 913,\n",
       " 'surfacey': 914,\n",
       " 'insight': 915,\n",
       " 'why': 916,\n",
       " 'instance': 917,\n",
       " 'good': 918,\n",
       " 'happen': 919,\n",
       " 'portrait': 920,\n",
       " 'alienation': 921,\n",
       " 'perfect': 922,\n",
       " 'certainly': 923,\n",
       " 'succeed': 924,\n",
       " 'alienating': 925,\n",
       " 'code': 926,\n",
       " 'talkers': 927,\n",
       " 'deserved': 928,\n",
       " 'hollow': 929,\n",
       " 'tribute': 930,\n",
       " 'skip': 931,\n",
       " 'philip': 932,\n",
       " 'glass': 933,\n",
       " 'soundtrack': 934,\n",
       " 'cd': 935,\n",
       " 'cold': 936,\n",
       " 'man': 937,\n",
       " 'motions': 938,\n",
       " 'dignified': 939,\n",
       " 'ceo': 940,\n",
       " 'meet': 941,\n",
       " 'rustic': 942,\n",
       " 'retreat': 943,\n",
       " 'pee': 944,\n",
       " 'tree': 945,\n",
       " 'bear': 946,\n",
       " 'laughter': 947,\n",
       " 'mechanical': 948,\n",
       " 'kinda': 949,\n",
       " 'goofy': 950,\n",
       " 'museum': 951,\n",
       " 'exhibit': 952,\n",
       " 'point': 953,\n",
       " 'view': 954,\n",
       " 'contemporary': 955,\n",
       " 'interpretation': 956,\n",
       " 'joan': 957,\n",
       " 'prefeminist': 958,\n",
       " 'plight': 959,\n",
       " 'left': 960,\n",
       " 'thinking': 961,\n",
       " 'present': 962,\n",
       " 'standards': 963,\n",
       " 'allow': 964,\n",
       " 'plenty': 965,\n",
       " 'nudity': 966,\n",
       " 'beware': 967,\n",
       " 'quirky': 968,\n",
       " 'brit': 969,\n",
       " 'turn': 970,\n",
       " 'dime': 971,\n",
       " 'oddly': 972,\n",
       " 'humorous': 973,\n",
       " 'tediously': 974,\n",
       " 'moments': 975,\n",
       " 'subplots': 976,\n",
       " 'gags': 977,\n",
       " 'mixed': 978,\n",
       " 'bag': 979,\n",
       " 'completely': 980,\n",
       " 'awful': 981,\n",
       " 'iranian': 982,\n",
       " 'grouchy': 983,\n",
       " 'ayatollah': 984,\n",
       " 'mosque': 985,\n",
       " 'trouble': 986,\n",
       " 'every': 987,\n",
       " 'day': 988,\n",
       " 'plodding': 989,\n",
       " 'extracting': 990,\n",
       " 'bare': 991,\n",
       " 'byatt': 992,\n",
       " 'purposes': 993,\n",
       " 'hollywood': 994,\n",
       " 'directors': 995,\n",
       " 'musker': 996,\n",
       " 'ron': 997,\n",
       " 'clements': 998,\n",
       " 'team': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.load import location, enc, mode\n",
    "\n",
    "data= 'sst1'\n",
    "with open(location(data, 'test'), 'r', encoding=enc(data)) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        #print(line)\n",
    "\n",
    "        if i==10:\n",
    "            break\n",
    "\n",
    "k = [location(data, m) for m in mode(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ukrainian: tob „соціс - центр соціальних та політичних досліджень)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = \"Ukrainian: TOB „СОЦІС - Центр соціальних та політичних досліджень)\"\n",
    "samp.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[5,2,7] + [0]*0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 17295\n",
      "train\t: torch.Size([76961, 58])\n",
      "train_label\t: torch.Size([76961])\n",
      "test\t: torch.Size([1821, 58])\n",
      "test_label\t: torch.Size([1821])\n",
      "dev\t: torch.Size([872, 58])\n",
      "dev_label\t: torch.Size([872])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17295, 300])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocess import load_data, build_wordvec\n",
    "\n",
    "data = 'sst2'\n",
    "dataset = load_data(data)\n",
    "\n",
    "for key, value in dataset.items():\n",
    "    if key == 'w2i':\n",
    "        print(f\"Vocab size : {len(value)}\")\n",
    "    else:\n",
    "        print(f\"{key}\\t: {value.shape}\")\n",
    "\n",
    "embed_mat = build_wordvec(dataset['w2i'], var=.01)\n",
    "embed_mat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning CNN in \"SST2\" set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 77.16, Max : 78.14: 100%|██████████| 50/50 [06:42<00:00,  8.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for RAND was 78.14 at 44^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 85.56, Max : 86.93: 100%|██████████| 50/50 [03:13<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for STATIC was 86.93 at 20^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 85.56, Max : 88.36: 100%|██████████| 50/50 [06:40<00:00,  8.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for NONSTATIC was 88.36 at 3^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc : 86.38, Max : 88.25: 100%|██████████| 50/50 [08:46<00:00, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for MULTICHANNEL was 88.25 at 8^th epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from src.model import CNN_New\n",
    "from src.trainer import Trainer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda:0'\n",
    "option = ['rand', 'static', 'nonstatic', 'multichannel'] # 'rand',\n",
    "\n",
    "\n",
    "print(f\"Tuning CNN in \\\"{data.upper()}\\\" set.\")\n",
    "for opt in option:\n",
    "    param = {\"MODEL\": opt   , \"VOCAB_SIZE\": embed_mat.shape[0]-2,\n",
    "        \"BATCH_SIZE\" : 50  , \"CLASS_SIZE\": max(dataset['train_label']) + 1,\n",
    "        \"WORD_DIM\" : 300   , \"FILTERS\": [3,4,5], \"FILTER_NUM\": 100,\n",
    "        \"MAX_SENT_LEN\" : dataset['train'].shape[1], \n",
    "        \"DROPOUT_PROB\": .5, \"WV_MATRIX\":embed_mat}\n",
    "    \n",
    "    model = CNN_New(**param).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # weight=len(data['train_label']) / torch.bincount(data['train_label']).to(torch.float)\n",
    "\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=1, rho=.95, weight_decay=0)\n",
    "    trainer = Trainer(model, criterion, optimizer, dataset, l2=9, device=device)\n",
    "\n",
    "    lst = []\n",
    "    timeiter = tqdm(range(50), position=0, leave=True)\n",
    "    m = 0\n",
    "    for i in timeiter:\n",
    "        trainer.train(1, show_batches=50, verbose=False)\n",
    "        l = trainer.test(verbose=False)\n",
    "        lst.append(l)\n",
    "        m = max(m, l)\n",
    "        timeiter.set_description(f\"Acc : {100*l:.2f}, Max : {100*m:.2f}\")\n",
    "    #trainer.plot()\n",
    "    Len = np.argmax(lst)\n",
    "    print(f\"Best Score for {opt.upper()} was {100*m:.2f} at {Len}^th epoch\")\n",
    "# drop = .3\n",
    "## rho =.9  HN 92/89/90/90 NH 89/88/91/91\n",
    "## rho =.95 HN 91/88/91/89 NH 90/89/91/89\n",
    "# drop = .5\n",
    "## rho =.9  HN 91/88/90/89 NH 90/89/90/\n",
    "#### BH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ TEST Result\n",
    "\n",
    "|       Model|SST1 |SST2 | CR  | MR  |TREC|MPQA |SUBJ|\n",
    "|---         |---  |---  |---  |---  |--- |---  | ---|\n",
    "|Random      |38.55|78.14|79.10|77.25|90.0|83.32|88.5|\n",
    "|Static      |45.79|86.93|78.04|76.21|88.0|81.62|92.9|\n",
    "|Non-Static  |48.51|88.36|78.84|76.46|89.0|83.41|93.9|\n",
    "|MultiChannel|48.33|88.25|79.37|74.70|88.4|82.94|93.9|\n",
    "|Should Be...|46.??|87.??|83.??|80.??|92.?|88.??|91.?|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 17400])\n",
      "[torch.Size([5, 100]), torch.Size([5, 100]), torch.Size([5, 100])]\n",
      "torch.Size([5, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5538,  0.5448],\n",
       "        [-0.7235,  0.1005],\n",
       "        [-0.7977, -0.0539],\n",
       "        [-0.1776, -0.0656],\n",
       "        [-0.7435,  0.8770]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model import CNN_New\n",
    "param = {\"MODEL\": 'rand'   , \"VOCAB_SIZE\": embed_mat.shape[0]-2,\n",
    "        \"BATCH_SIZE\" : 50  , \"CLASS_SIZE\": max(dataset['train_label']) + 1,\n",
    "        \"WORD_DIM\" : 300   , \"FILTERS\": [3,4,5], \"FILTER_NUM\": 100,\n",
    "        \"MAX_SENT_LEN\" : dataset['train'].shape[1], \n",
    "        \"DROPOUT_PROB\": .5, \"WV_MATRIX\":embed_mat}\n",
    "    \n",
    "model = CNN_New(**param)\n",
    "\n",
    "model(dataset['train'][:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.tensor([1])\n",
    "k.repeat(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.15958634868825"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(np.exp([3,2,1.1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freshman01",
   "language": "python",
   "name": "freshman01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7630cfb9cc60cb9709f67712e275111c5e1bba9b718b36e51626f2087c2ff988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
